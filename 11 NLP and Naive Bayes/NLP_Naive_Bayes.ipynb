{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 11: NLP and Naive Bayes\n",
    "\n",
    "## Text Classification and Sentiment Analysis on Blog Posts\n",
    "\n",
    "**Topics Covered:**\n",
    "- Text Preprocessing (Tokenization, Stopwords, Cleaning)\n",
    "- TF-IDF Feature Extraction\n",
    "- Naive Bayes Classification\n",
    "- Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1: Import Libraries and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import string\n",
    "\n",
    "# NLP libraries\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from textblob import TextBlob\n",
    "\n",
    "# ML libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('blogs.csv')\n",
    "\n",
    "print(\"Dataset loaded! Shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2: Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data info\n",
    "print(\"=== Data Info ===\")\n",
    "print(df.dtypes)\n",
    "print(\"\\n=== Missing Values ===\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category distribution\n",
    "print(\"=== Category Distribution ===\")\n",
    "category_counts = df['Labels'].value_counts()\n",
    "print(category_counts)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(category_counts.index, category_counts.values, color='steelblue')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Blog Categories')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.savefig('category_distribution.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample text\n",
    "print(\"=== Sample Blog Post ===\")\n",
    "print(df['Data'].iloc[0][:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3: Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text cleaning function\n",
    "def clean_text(text):\n",
    "    # Convert to string\n",
    "    text = str(text)\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove email addresses\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+', '', text)\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Apply cleaning\n",
    "print(\"=== Cleaning Text ===\")\n",
    "df['cleaned_text'] = df['Data'].apply(clean_text)\n",
    "print(\"Text cleaning complete!\")\n",
    "\n",
    "print(\"\\nBefore cleaning:\")\n",
    "print(df['Data'].iloc[0][:200])\n",
    "print(\"\\nAfter cleaning:\")\n",
    "print(df['cleaned_text'].iloc[0][:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stopwords\n",
    "def remove_stopwords(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = text.split()\n",
    "    \n",
    "    filtered_words = []\n",
    "    for word in words:\n",
    "        if word not in stop_words:\n",
    "            filtered_words.append(word)\n",
    "    \n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "print(\"=== Removing Stopwords ===\")\n",
    "df['processed_text'] = df['cleaned_text'].apply(remove_stopwords)\n",
    "print(\"Stopwords removed!\")\n",
    "\n",
    "print(\"\\nAfter stopword removal:\")\n",
    "print(df['processed_text'].iloc[0][:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4: Feature Extraction (TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Vectorization\n",
    "print(\"=== TF-IDF Feature Extraction ===\")\n",
    "\n",
    "# Create TF-IDF vectorizer\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "# Fit and transform\n",
    "X = tfidf.fit_transform(df['processed_text'])\n",
    "y = df['Labels']\n",
    "\n",
    "print(\"TF-IDF matrix shape:\", X.shape)\n",
    "print(\"Number of features (words):\", len(tfidf.get_feature_names_out()))\n",
    "\n",
    "# Show sample features\n",
    "print(\"\\nSample features (words):\")\n",
    "print(tfidf.get_feature_names_out()[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training set:\", X_train.shape[0])\n",
    "print(\"Testing set:\", X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 5: Naive Bayes Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Naive Bayes model\n",
    "print(\"=== Training Naive Bayes ===\")\n",
    "\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Model trained!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = nb_model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(\"=== Model Evaluation ===\")\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(\"Accuracy:\", round(accuracy, 4))\n",
    "print(\"Precision:\", round(precision, 4))\n",
    "print(\"Recall:\", round(recall, 4))\n",
    "print(\"F1-Score:\", round(f1, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix - Naive Bayes')\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 6: Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment Analysis using TextBlob\n",
    "print(\"=== Sentiment Analysis ===\")\n",
    "\n",
    "def get_sentiment(text):\n",
    "    # Get polarity score (-1 to 1)\n",
    "    blob = TextBlob(str(text))\n",
    "    polarity = blob.sentiment.polarity\n",
    "    \n",
    "    # Classify sentiment\n",
    "    if polarity > 0.1:\n",
    "        return 'Positive'\n",
    "    elif polarity < -0.1:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "# Apply sentiment analysis\n",
    "df['sentiment'] = df['Data'].apply(get_sentiment)\n",
    "\n",
    "print(\"Sentiment analysis complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment distribution\n",
    "print(\"=== Sentiment Distribution ===\")\n",
    "sentiment_counts = df['sentiment'].value_counts()\n",
    "print(sentiment_counts)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "colors = {'Positive': 'green', 'Neutral': 'gray', 'Negative': 'red'}\n",
    "plt.bar(sentiment_counts.index, sentiment_counts.values, \n",
    "        color=[colors[s] for s in sentiment_counts.index])\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Sentiments')\n",
    "plt.savefig('sentiment_distribution.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment by Category\n",
    "print(\"=== Sentiment by Category ===\")\n",
    "\n",
    "sentiment_by_category = pd.crosstab(df['Labels'], df['sentiment'])\n",
    "print(sentiment_by_category)\n",
    "\n",
    "# Plot\n",
    "sentiment_by_category.plot(kind='bar', figsize=(12, 6), color=['red', 'gray', 'green'])\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Sentiment Distribution by Category')\n",
    "plt.legend(title='Sentiment')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.savefig('sentiment_by_category.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "1. **Text Classification:**\n",
    "   - Naive Bayes performed well on blog post classification\n",
    "   - TF-IDF effectively captured important words for each category\n",
    "\n",
    "2. **Sentiment Analysis:**\n",
    "   - Most blog posts have neutral sentiment\n",
    "   - Different categories show different sentiment patterns\n",
    "\n",
    "### Topics Covered:\n",
    "- Text preprocessing (cleaning, tokenization, stopword removal)\n",
    "- TF-IDF feature extraction\n",
    "- Multinomial Naive Bayes classification\n",
    "- Sentiment analysis using TextBlob"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
