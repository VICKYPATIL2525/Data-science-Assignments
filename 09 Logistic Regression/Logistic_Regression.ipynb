{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 9: Logistic Regression\n",
    "\n",
    "## Dataset: Titanic Survival Prediction\n",
    "\n",
    "**Objective:** Predict passenger survival using Logistic Regression.\n",
    "\n",
    "**Topics Covered:**\n",
    "- Logistic Regression\n",
    "- Binary Classification\n",
    "- ROC Curve and AUC\n",
    "- Model Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1: Import Libraries and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
    "\n",
    "# Load the dataset\n",
    "df_train = pd.read_csv('Titanic_train.csv')\n",
    "df_test = pd.read_csv('Titanic_test.csv')\n",
    "\n",
    "print(\"Training set loaded! Shape:\", df_train.shape)\n",
    "print(\"Testing set loaded! Shape:\", df_test.shape)\n",
    "print(\"\\nFirst 5 rows of training data:\")\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2: Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types and summary\n",
    "print(\"=== Data Types ===\")\n",
    "print(df_train.dtypes)\n",
    "\n",
    "print(\"\\n=== Summary Statistics ===\")\n",
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing values\n",
    "print(\"=== Missing Values ===\")\n",
    "missing = df_train.isnull().sum()\n",
    "missing_pct = (missing / len(df_train)) * 100\n",
    "\n",
    "for col in df_train.columns:\n",
    "    if missing[col] > 0:\n",
    "        print(col + \":\", missing[col], \"(\", round(missing_pct[col], 2), \"%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variable distribution\n",
    "print(\"=== Survival Distribution ===\")\n",
    "survival_counts = df_train['Survived'].value_counts()\n",
    "print(survival_counts)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(['Not Survived', 'Survived'], survival_counts.values, color=['red', 'green'])\n",
    "plt.xlabel('Survival Status')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Survival Distribution')\n",
    "\n",
    "for i in range(len(survival_counts)):\n",
    "    plt.text(i, survival_counts.values[i] + 10, str(survival_counts.values[i]), ha='center')\n",
    "\n",
    "plt.savefig('survival_distribution.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Survival by Sex\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sex_survival = df_train.groupby('Sex')['Survived'].mean()\n",
    "plt.bar(sex_survival.index, sex_survival.values, color=['blue', 'pink'])\n",
    "plt.xlabel('Sex')\n",
    "plt.ylabel('Survival Rate')\n",
    "plt.title('Survival Rate by Sex')\n",
    "\n",
    "# Survival by Pclass\n",
    "plt.subplot(1, 2, 2)\n",
    "class_survival = df_train.groupby('Pclass')['Survived'].mean()\n",
    "plt.bar(['1st', '2nd', '3rd'], class_survival.values, color=['gold', 'silver', 'brown'])\n",
    "plt.xlabel('Passenger Class')\n",
    "plt.ylabel('Survival Rate')\n",
    "plt.title('Survival Rate by Class')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('survival_analysis.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age distribution\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(df_train['Age'].dropna(), bins=30, color='steelblue', edgecolor='black')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Age Distribution')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(df_train['Fare'], bins=30, color='green', edgecolor='black')\n",
    "plt.xlabel('Fare')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Fare Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('distributions.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy for preprocessing\n",
    "df = df_train.copy()\n",
    "\n",
    "# Handle missing values\n",
    "print(\"=== Handling Missing Values ===\")\n",
    "\n",
    "# Fill Age with median\n",
    "age_median = df['Age'].median()\n",
    "df['Age'] = df['Age'].fillna(age_median)\n",
    "print(\"Filled Age with median:\", age_median)\n",
    "\n",
    "# Fill Embarked with mode\n",
    "embarked_mode = df['Embarked'].mode()[0]\n",
    "df['Embarked'] = df['Embarked'].fillna(embarked_mode)\n",
    "print(\"Filled Embarked with mode:\", embarked_mode)\n",
    "\n",
    "# Drop Cabin (too many missing values)\n",
    "df = df.drop('Cabin', axis=1)\n",
    "print(\"Dropped Cabin column\")\n",
    "\n",
    "print(\"\\nRemaining missing values:\", df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables\n",
    "print(\"=== Encoding Categorical Variables ===\")\n",
    "\n",
    "# Encode Sex (Male=1, Female=0)\n",
    "df['Sex_encoded'] = df['Sex'].apply(lambda x: 1 if x == 'male' else 0)\n",
    "print(\"Sex: male=1, female=0\")\n",
    "\n",
    "# Encode Embarked\n",
    "embarked_mapping = {'S': 0, 'C': 1, 'Q': 2}\n",
    "df['Embarked_encoded'] = df['Embarked'].map(embarked_mapping)\n",
    "print(\"Embarked: S=0, C=1, Q=2\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for model\n",
    "feature_cols = ['Pclass', 'Sex_encoded', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked_encoded']\n",
    "\n",
    "X = df[feature_cols]\n",
    "y = df['Survived']\n",
    "\n",
    "print(\"Features:\", feature_cols)\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training set:\", len(X_train))\n",
    "print(\"Testing set:\", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Features scaled using StandardScaler\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4: Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Logistic Regression model\n",
    "print(\"=== Training Logistic Regression Model ===\")\n",
    "\n",
    "model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Model trained successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print(\"Predictions made on test set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 5: Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "print(\"=== Model Evaluation ===\")\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(\"Accuracy:\", round(accuracy, 4))\n",
    "print(\"Precision:\", round(precision, 4))\n",
    "print(\"Recall:\", round(recall, 4))\n",
    "print(\"F1-Score:\", round(f1, 4))\n",
    "print(\"ROC-AUC:\", round(roc_auc, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Not Survived', 'Survived'],\n",
    "            yticklabels=['Not Survived', 'Survived'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig('confusion_matrix.png')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTrue Negatives:\", cm[0][0])\n",
    "print(\"False Positives:\", cm[0][1])\n",
    "print(\"False Negatives:\", cm[1][0])\n",
    "print(\"True Positives:\", cm[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve\n",
    "print(\"=== ROC Curve ===\")\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', label='ROC Curve (AUC = ' + str(round(roc_auc, 4)) + ')')\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--', label='Random Classifier')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('roc_curve.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Not Survived', 'Survived']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 6: Model Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpret coefficients\n",
    "print(\"=== Logistic Regression Coefficients ===\")\n",
    "\n",
    "coefficients = model.coef_[0]\n",
    "intercept = model.intercept_[0]\n",
    "\n",
    "print(\"\\nIntercept:\", round(intercept, 4))\n",
    "print(\"\\nCoefficients:\")\n",
    "for i in range(len(feature_cols)):\n",
    "    coef = coefficients[i]\n",
    "    feature = feature_cols[i]\n",
    "    print(\"  \" + feature + \":\", round(coef, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance (based on absolute coefficient value)\n",
    "print(\"=== Feature Importance ===\")\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_cols,\n",
    "    'Coefficient': coefficients,\n",
    "    'Abs_Coefficient': np.abs(coefficients)\n",
    "})\n",
    "\n",
    "importance_df = importance_df.sort_values('Abs_Coefficient', ascending=True)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "colors = ['green' if c > 0 else 'red' for c in importance_df['Coefficient']]\n",
    "plt.barh(importance_df['Feature'], importance_df['Coefficient'], color=colors)\n",
    "plt.xlabel('Coefficient')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Logistic Regression Coefficients')\n",
    "plt.axvline(x=0, color='black', linestyle='-', linewidth=0.5)\n",
    "plt.savefig('feature_importance.png')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"- Positive coefficient = increases survival probability\")\n",
    "print(\"- Negative coefficient = decreases survival probability\")\n",
    "print(\"- Sex_encoded (negative): Being male reduces survival chances\")\n",
    "print(\"- Pclass (negative): Higher class number (3rd class) reduces survival\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 7: Save Model for Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model for Streamlit deployment\n",
    "import pickle\n",
    "\n",
    "# Save model\n",
    "with open('logistic_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "# Save scaler\n",
    "with open('scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "print(\"Model and scaler saved for deployment!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Interview Questions\n",
    "\n",
    "### 1. Difference between Precision and Recall\n",
    "\n",
    "| Metric | Formula | Meaning |\n",
    "|--------|---------|--------|\n",
    "| **Precision** | TP / (TP + FP) | Of all predicted positives, how many are actually positive? |\n",
    "| **Recall** | TP / (TP + FN) | Of all actual positives, how many did we correctly predict? |\n",
    "\n",
    "**When to use which:**\n",
    "- **High Precision needed:** When false positives are costly (e.g., spam detection)\n",
    "- **High Recall needed:** When false negatives are costly (e.g., disease detection)\n",
    "\n",
    "### 2. Cross-Validation in Binary Classification\n",
    "\n",
    "**What is Cross-Validation?**\n",
    "- Technique to evaluate model by splitting data into multiple folds\n",
    "- Train on some folds, test on remaining fold\n",
    "- Repeat for all folds and average results\n",
    "\n",
    "**Why is it important?**\n",
    "1. Gives more reliable estimate of model performance\n",
    "2. Reduces overfitting by testing on different data subsets\n",
    "3. Uses all data for both training and testing\n",
    "4. Helps in hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "In this assignment, we:\n",
    "\n",
    "1. **Explored** the Titanic dataset and visualized survival patterns\n",
    "2. **Preprocessed** data by handling missing values and encoding categoricals\n",
    "3. **Built** a Logistic Regression model\n",
    "4. **Evaluated** using accuracy, precision, recall, F1, and ROC-AUC\n",
    "5. **Interpreted** coefficients to understand feature importance\n",
    "6. **Saved** model for Streamlit deployment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
