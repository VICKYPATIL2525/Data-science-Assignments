{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 10: Support Vector Machine (SVM)\n",
    "\n",
    "## Dataset: Mushroom Classification\n",
    "\n",
    "**Objective:** Classify mushrooms as edible or poisonous using SVM.\n",
    "\n",
    "**Topics Covered:**\n",
    "- SVM Classifier\n",
    "- Different Kernels (Linear, RBF, Polynomial)\n",
    "- Hyperparameter Tuning\n",
    "- Model Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1: Import Libraries and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('mushroom.csv')\n",
    "\n",
    "print(\"Dataset loaded successfully!\")\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2: Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data info\n",
    "print(\"=== Data Types ===\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\n=== Missing Values ===\")\n",
    "print(df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target distribution\n",
    "print(\"=== Class Distribution ===\")\n",
    "class_counts = df['class'].value_counts()\n",
    "print(class_counts)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(['Edible', 'Poisonous'], class_counts.values, color=['green', 'red'])\n",
    "plt.xlabel('Mushroom Class')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Mushroom Classes')\n",
    "plt.savefig('class_distribution.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical columns distribution\n",
    "numerical_cols = ['stalk_height', 'cap_diameter']\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "for i in range(len(numerical_cols)):\n",
    "    col = numerical_cols[i]\n",
    "    axes[i].hist(df[col], bins=30, color='steelblue', edgecolor='black')\n",
    "    axes[i].set_title('Distribution of ' + col)\n",
    "    axes[i].set_xlabel(col)\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('numerical_distributions.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "for i in range(len(numerical_cols)):\n",
    "    col = numerical_cols[i]\n",
    "    axes[i].boxplot(df[col].dropna())\n",
    "    axes[i].set_title('Boxplot of ' + col)\n",
    "    axes[i].set_ylabel(col)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('boxplots.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnamed column if exists\n",
    "if 'Unnamed: 0' in df.columns:\n",
    "    df = df.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "categorical_cols.remove('class')  # Remove target\n",
    "\n",
    "print(\"Categorical columns:\", len(categorical_cols))\n",
    "print(\"Numerical columns:\", len(numerical_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables\n",
    "print(\"=== Encoding Categorical Variables ===\")\n",
    "\n",
    "df_encoded = df.copy()\n",
    "label_encoders = {}\n",
    "\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df_encoded[col] = le.fit_transform(df_encoded[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Encode target\n",
    "le_target = LabelEncoder()\n",
    "df_encoded['class'] = le_target.fit_transform(df_encoded['class'])\n",
    "print(\"Target encoding: edible=0, poisonous=1\")\n",
    "\n",
    "print(\"\\nEncoding complete!\")\n",
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target\n",
    "feature_cols = [col for col in df_encoded.columns if col != 'class']\n",
    "\n",
    "X = df_encoded[feature_cols]\n",
    "y = df_encoded['class']\n",
    "\n",
    "print(\"Features shape:\", X.shape)\n",
    "print(\"Target shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training set:\", len(X_train))\n",
    "print(\"Testing set:\", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Features scaled!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4: SVM Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train SVM with default parameters (RBF kernel)\n",
    "print(\"=== Training SVM Model (RBF Kernel) ===\")\n",
    "\n",
    "svm_rbf = SVC(kernel='rbf', random_state=42)\n",
    "svm_rbf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_rbf = svm_rbf.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate\n",
    "accuracy = accuracy_score(y_test, y_pred_rbf)\n",
    "precision = precision_score(y_test, y_pred_rbf)\n",
    "recall = recall_score(y_test, y_pred_rbf)\n",
    "f1 = f1_score(y_test, y_pred_rbf)\n",
    "\n",
    "print(\"\\nRBF Kernel Results:\")\n",
    "print(\"Accuracy:\", round(accuracy, 4))\n",
    "print(\"Precision:\", round(precision, 4))\n",
    "print(\"Recall:\", round(recall, 4))\n",
    "print(\"F1-Score:\", round(f1, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_rbf)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Edible', 'Poisonous'],\n",
    "            yticklabels=['Edible', 'Poisonous'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix (RBF Kernel)')\n",
    "plt.savefig('confusion_matrix.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 5: Compare Different Kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different kernels\n",
    "print(\"=== Comparing SVM Kernels ===\")\n",
    "\n",
    "kernels = ['linear', 'rbf', 'poly', 'sigmoid']\n",
    "results = []\n",
    "\n",
    "for kernel in kernels:\n",
    "    print(\"\\nTraining with\", kernel, \"kernel...\")\n",
    "    \n",
    "    # Train model\n",
    "    svm_model = SVC(kernel=kernel, random_state=42)\n",
    "    svm_model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred = svm_model.predict(X_test_scaled)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    f1_val = f1_score(y_test, y_pred)\n",
    "    \n",
    "    results.append({\n",
    "        'Kernel': kernel,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1-Score': f1_val\n",
    "    })\n",
    "    \n",
    "    print(\"  Accuracy:\", round(acc, 4))\n",
    "\n",
    "# Create comparison dataframe\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\n=== Kernel Comparison ===\")\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot kernel comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "x_pos = range(len(kernels))\n",
    "plt.bar(x_pos, results_df['Accuracy'], color='steelblue', edgecolor='black')\n",
    "plt.xticks(x_pos, results_df['Kernel'])\n",
    "plt.xlabel('Kernel Type')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('SVM Accuracy by Kernel Type')\n",
    "plt.ylim(0.9, 1.0)\n",
    "\n",
    "for i in range(len(results_df)):\n",
    "    plt.text(i, results_df['Accuracy'].iloc[i] + 0.005, \n",
    "             str(round(results_df['Accuracy'].iloc[i], 4)), ha='center')\n",
    "\n",
    "plt.savefig('kernel_comparison.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 6: Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning for RBF kernel\n",
    "print(\"=== Hyperparameter Tuning (RBF Kernel) ===\")\n",
    "\n",
    "C_values = [0.1, 1, 10, 100]\n",
    "gamma_values = ['scale', 'auto', 0.1, 1]\n",
    "\n",
    "best_accuracy = 0\n",
    "best_params = {}\n",
    "\n",
    "for C in C_values:\n",
    "    for gamma in gamma_values:\n",
    "        svm_model = SVC(kernel='rbf', C=C, gamma=gamma, random_state=42)\n",
    "        svm_model.fit(X_train_scaled, y_train)\n",
    "        y_pred = svm_model.predict(X_test_scaled)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        if acc > best_accuracy:\n",
    "            best_accuracy = acc\n",
    "            best_params = {'C': C, 'gamma': gamma}\n",
    "\n",
    "print(\"\\nBest Parameters:\")\n",
    "print(\"  C:\", best_params['C'])\n",
    "print(\"  gamma:\", best_params['gamma'])\n",
    "print(\"  Best Accuracy:\", round(best_accuracy, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final model with best parameters\n",
    "print(\"=== Training Final Model ===\")\n",
    "\n",
    "final_svm = SVC(kernel='rbf', C=best_params['C'], gamma=best_params['gamma'], random_state=42)\n",
    "final_svm.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_final = final_svm.predict(X_test_scaled)\n",
    "\n",
    "print(\"\\n=== Final Model Evaluation ===\")\n",
    "print(classification_report(y_test, y_pred_final, target_names=['Edible', 'Poisonous']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 7: Analysis and Discussion\n",
    "\n",
    "### SVM Strengths:\n",
    "1. **Effective in high-dimensional spaces** - Works well even when features > samples\n",
    "2. **Memory efficient** - Uses only support vectors for decision function\n",
    "3. **Versatile** - Different kernels for different data types\n",
    "\n",
    "### SVM Weaknesses:\n",
    "1. **Computationally expensive** for large datasets\n",
    "2. **Sensitive to feature scaling** - Requires normalization\n",
    "3. **Difficult to interpret** - Black-box model\n",
    "\n",
    "### Practical Implications:\n",
    "- SVM is excellent for binary classification like mushroom edibility\n",
    "- RBF kernel is good default for non-linear data\n",
    "- Hyperparameter tuning (C, gamma) significantly impacts performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "In this assignment, we:\n",
    "\n",
    "1. **Explored** the Mushroom dataset\n",
    "2. **Preprocessed** data with label encoding and scaling\n",
    "3. **Implemented** SVM with multiple kernels\n",
    "4. **Compared** Linear, RBF, Polynomial, and Sigmoid kernels\n",
    "5. **Tuned** hyperparameters C and gamma\n",
    "6. **Analyzed** SVM strengths and weaknesses"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
