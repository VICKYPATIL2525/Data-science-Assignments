{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 7: Decision Tree Classification\n",
    "\n",
    "## Dataset: Heart Disease Prediction\n",
    "\n",
    "**Objective:** Apply Decision Tree Classification to predict heart disease.\n",
    "\n",
    "**Topics Covered:**\n",
    "- Data Preparation and EDA\n",
    "- Feature Engineering\n",
    "- Decision Tree Classification\n",
    "- Hyperparameter Tuning\n",
    "- Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1: Import Libraries and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine Learning libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the dataset (second sheet contains the data)\n",
    "df = pd.read_excel('heart_disease.xlsx', sheet_name=1)\n",
    "\n",
    "print(\"Dataset loaded successfully!\")\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2: Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types and info\n",
    "print(\"=== Dataset Info ===\")\n",
    "print(df.dtypes)\n",
    "print(\"\\n=== Statistical Summary ===\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"=== Missing Values ===\")\n",
    "missing = df.isnull().sum()\n",
    "print(missing)\n",
    "print(\"\\nTotal missing:\", missing.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check unique values in categorical columns\n",
    "print(\"=== Unique Values in Categorical Columns ===\")\n",
    "categorical_cols = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'thal']\n",
    "\n",
    "for col in categorical_cols:\n",
    "    print(col + \":\", df[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variable distribution\n",
    "print(\"=== Target Variable (num) Distribution ===\")\n",
    "target_counts = df['num'].value_counts()\n",
    "print(target_counts)\n",
    "\n",
    "# Convert to binary (0 = no disease, 1 = disease)\n",
    "# Original: 0, 1, 2, 3, 4 (stages of heart disease)\n",
    "# Binary: 0 = no disease, 1 = has disease\n",
    "df['target'] = df['num'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "print(\"\\nAfter converting to binary:\")\n",
    "print(df['target'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize target distribution\n",
    "plt.figure(figsize=(8, 5))\n",
    "colors = ['green', 'red']\n",
    "target_counts = df['target'].value_counts()\n",
    "plt.bar(['No Disease', 'Has Disease'], target_counts.values, color=colors)\n",
    "plt.xlabel('Heart Disease Status')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Heart Disease')\n",
    "\n",
    "# Add count labels\n",
    "for i in range(len(target_counts)):\n",
    "    plt.text(i, target_counts.values[i] + 10, str(target_counts.values[i]), ha='center')\n",
    "\n",
    "plt.savefig('target_distribution.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograms for numerical columns\n",
    "numerical_cols = ['age', 'trestbps', 'chol', 'thalch', 'oldpeak']\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(len(numerical_cols)):\n",
    "    col = numerical_cols[i]\n",
    "    axes[i].hist(df[col], bins=30, color='steelblue', edgecolor='black')\n",
    "    axes[i].set_title('Distribution of ' + col)\n",
    "    axes[i].set_xlabel(col)\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "\n",
    "# Hide last subplot\n",
    "axes[5].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('histograms.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplots to check for outliers\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(len(numerical_cols)):\n",
    "    col = numerical_cols[i]\n",
    "    axes[i].boxplot(df[col].dropna())\n",
    "    axes[i].set_title('Boxplot of ' + col)\n",
    "    axes[i].set_ylabel(col)\n",
    "\n",
    "axes[5].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('boxplots.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3: Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "print(\"=== Handling Missing Values ===\")\n",
    "\n",
    "# Fill numerical missing values with median\n",
    "for col in numerical_cols:\n",
    "    if df[col].isnull().sum() > 0:\n",
    "        median_val = df[col].median()\n",
    "        df[col] = df[col].fillna(median_val)\n",
    "        print(\"Filled\", col, \"with median:\", median_val)\n",
    "\n",
    "# Fill categorical missing values with mode\n",
    "for col in categorical_cols:\n",
    "    if df[col].isnull().sum() > 0:\n",
    "        mode_val = df[col].mode()[0]\n",
    "        df[col] = df[col].fillna(mode_val)\n",
    "        print(\"Filled\", col, \"with mode:\", mode_val)\n",
    "\n",
    "print(\"\\nRemaining missing values:\", df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables using Label Encoding\n",
    "print(\"=== Label Encoding Categorical Variables ===\")\n",
    "\n",
    "# Create a copy for encoding\n",
    "df_encoded = df.copy()\n",
    "\n",
    "# Apply label encoding to categorical columns\n",
    "label_encoders = {}\n",
    "\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df_encoded[col] = le.fit_transform(df_encoded[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "    print(col + \":\")\n",
    "    print(\"  Original:\", list(le.classes_))\n",
    "    print(\"  Encoded:\", list(range(len(le.classes_))))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Select only numerical columns for correlation\n",
    "numeric_df = df_encoded[numerical_cols + categorical_cols + ['target']]\n",
    "correlation = numeric_df.corr()\n",
    "\n",
    "sns.heatmap(correlation, annot=True, fmt='.2f', cmap='coolwarm', center=0)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.savefig('correlation_matrix.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4: Decision Tree Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target\n",
    "print(\"=== Preparing Data for Model ===\")\n",
    "\n",
    "# Features (X) - all columns except 'num' and 'target'\n",
    "feature_cols = numerical_cols + categorical_cols\n",
    "X = df_encoded[feature_cols]\n",
    "\n",
    "# Target (y)\n",
    "y = df_encoded['target']\n",
    "\n",
    "print(\"Features shape:\", X.shape)\n",
    "print(\"Target shape:\", y.shape)\n",
    "print(\"\\nFeature columns:\", feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets (80-20 split)\n",
    "print(\"=== Train-Test Split ===\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training set size:\", len(X_train))\n",
    "print(\"Testing set size:\", len(X_test))\n",
    "print(\"\\nTraining percentage:\", round(len(X_train)/len(X)*100, 1), \"%\")\n",
    "print(\"Testing percentage:\", round(len(X_test)/len(X)*100, 1), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train Decision Tree model\n",
    "print(\"=== Training Decision Tree Model ===\")\n",
    "\n",
    "# Create model with default parameters\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Model trained successfully!\")\n",
    "print(\"\\nModel parameters:\")\n",
    "print(\"  Max depth:\", dt_model.max_depth)\n",
    "print(\"  Min samples split:\", dt_model.min_samples_split)\n",
    "print(\"  Criterion:\", dt_model.criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = dt_model.predict(X_test)\n",
    "y_pred_proba = dt_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Predictions made on test set\")\n",
    "print(\"\\nSample predictions (first 10):\")\n",
    "for i in range(10):\n",
    "    print(\"Actual:\", y_test.iloc[i], \"| Predicted:\", y_pred[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model performance\n",
    "print(\"=== Model Evaluation (Default Parameters) ===\")\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(\"Accuracy:\", round(accuracy, 4))\n",
    "print(\"Precision:\", round(precision, 4))\n",
    "print(\"Recall:\", round(recall, 4))\n",
    "print(\"F1-Score:\", round(f1, 4))\n",
    "print(\"ROC-AUC:\", round(roc_auc, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['No Disease', 'Has Disease'],\n",
    "            yticklabels=['No Disease', 'Has Disease'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig('confusion_matrix.png')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"True Negatives:\", cm[0][0])\n",
    "print(\"False Positives:\", cm[0][1])\n",
    "print(\"False Negatives:\", cm[1][0])\n",
    "print(\"True Positives:\", cm[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test, y_pred, target_names=['No Disease', 'Has Disease']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 5: Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Tuning\n",
    "print(\"=== Hyperparameter Tuning ===\")\n",
    "print(\"\")\n",
    "print(\"Testing different values for:\")\n",
    "print(\"- max_depth: Maximum depth of tree\")\n",
    "print(\"- min_samples_split: Minimum samples to split a node\")\n",
    "print(\"- criterion: 'gini' or 'entropy'\")\n",
    "print(\"\")\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "\n",
    "# Try different combinations\n",
    "max_depths = [3, 5, 7, 10, None]\n",
    "min_samples_splits = [2, 5, 10]\n",
    "criterions = ['gini', 'entropy']\n",
    "\n",
    "best_accuracy = 0\n",
    "best_params = {}\n",
    "\n",
    "for depth in max_depths:\n",
    "    for min_split in min_samples_splits:\n",
    "        for criterion in criterions:\n",
    "            # Create and train model\n",
    "            model = DecisionTreeClassifier(\n",
    "                max_depth=depth,\n",
    "                min_samples_split=min_split,\n",
    "                criterion=criterion,\n",
    "                random_state=42\n",
    "            )\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Evaluate\n",
    "            y_pred_temp = model.predict(X_test)\n",
    "            acc = accuracy_score(y_test, y_pred_temp)\n",
    "            \n",
    "            # Store result\n",
    "            results.append({\n",
    "                'max_depth': depth,\n",
    "                'min_samples_split': min_split,\n",
    "                'criterion': criterion,\n",
    "                'accuracy': acc\n",
    "            })\n",
    "            \n",
    "            # Update best\n",
    "            if acc > best_accuracy:\n",
    "                best_accuracy = acc\n",
    "                best_params = {\n",
    "                    'max_depth': depth,\n",
    "                    'min_samples_split': min_split,\n",
    "                    'criterion': criterion\n",
    "                }\n",
    "\n",
    "print(\"Tuning complete!\")\n",
    "print(\"\\nBest parameters found:\")\n",
    "print(\"  max_depth:\", best_params['max_depth'])\n",
    "print(\"  min_samples_split:\", best_params['min_samples_split'])\n",
    "print(\"  criterion:\", best_params['criterion'])\n",
    "print(\"\\nBest accuracy:\", round(best_accuracy, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model with best parameters\n",
    "print(\"=== Training Model with Best Parameters ===\")\n",
    "\n",
    "best_model = DecisionTreeClassifier(\n",
    "    max_depth=best_params['max_depth'],\n",
    "    min_samples_split=best_params['min_samples_split'],\n",
    "    criterion=best_params['criterion'],\n",
    "    random_state=42\n",
    ")\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "y_pred_proba_best = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy_best = accuracy_score(y_test, y_pred_best)\n",
    "precision_best = precision_score(y_test, y_pred_best)\n",
    "recall_best = recall_score(y_test, y_pred_best)\n",
    "f1_best = f1_score(y_test, y_pred_best)\n",
    "roc_auc_best = roc_auc_score(y_test, y_pred_proba_best)\n",
    "\n",
    "print(\"\\n=== Tuned Model Performance ===\")\n",
    "print(\"Accuracy:\", round(accuracy_best, 4))\n",
    "print(\"Precision:\", round(precision_best, 4))\n",
    "print(\"Recall:\", round(recall_best, 4))\n",
    "print(\"F1-Score:\", round(f1_best, 4))\n",
    "print(\"ROC-AUC:\", round(roc_auc_best, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 6: Model Visualization and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the Decision Tree\n",
    "print(\"=== Decision Tree Visualization ===\")\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(best_model, \n",
    "          feature_names=feature_cols,\n",
    "          class_names=['No Disease', 'Has Disease'],\n",
    "          filled=True,\n",
    "          rounded=True,\n",
    "          fontsize=10,\n",
    "          max_depth=3)  # Show only first 3 levels for clarity\n",
    "plt.title('Decision Tree (First 3 Levels)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('decision_tree.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance\n",
    "print(\"=== Feature Importance ===\")\n",
    "\n",
    "# Get feature importances\n",
    "importances = best_model.feature_importances_\n",
    "\n",
    "# Create dataframe for visualization\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_cols,\n",
    "    'Importance': importances\n",
    "})\n",
    "\n",
    "# Sort by importance\n",
    "importance_df = importance_df.sort_values('Importance', ascending=True)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(importance_df['Feature'], importance_df['Importance'], color='steelblue')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Feature Importance in Decision Tree')\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_importance.png')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 5 Most Important Features:\")\n",
    "top_features = importance_df.sort_values('Importance', ascending=False).head(5)\n",
    "for i in range(len(top_features)):\n",
    "    row = top_features.iloc[i]\n",
    "    print(str(i+1) + \".\", row['Feature'], \"-\", round(row['Importance'], 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve\n",
    "print(\"=== ROC Curve ===\")\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba_best)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', label='ROC Curve (AUC = ' + str(round(roc_auc_best, 4)) + ')')\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--', label='Random Classifier')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('roc_curve.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Interview Questions\n",
    "\n",
    "### 1. Common Hyperparameters of Decision Trees\n",
    "\n",
    "| Hyperparameter | Description | Effect |\n",
    "|----------------|-------------|--------|\n",
    "| **max_depth** | Maximum depth of tree | Higher = more complex, may overfit |\n",
    "| **min_samples_split** | Minimum samples to split a node | Higher = less complex, prevents overfitting |\n",
    "| **min_samples_leaf** | Minimum samples in leaf node | Higher = smoother decision boundary |\n",
    "| **criterion** | Splitting criterion (gini/entropy) | Gini is faster, entropy may give slightly better results |\n",
    "| **max_features** | Number of features to consider | Lower = more randomness, reduces overfitting |\n",
    "\n",
    "### 2. Label Encoding vs One-Hot Encoding\n",
    "\n",
    "| Aspect | Label Encoding | One-Hot Encoding |\n",
    "|--------|---------------|------------------|\n",
    "| **Method** | Assigns numbers (0,1,2...) | Creates binary columns |\n",
    "| **Columns** | Same number of columns | Creates many new columns |\n",
    "| **Assumption** | Implies ordinal relationship | No ordinal assumption |\n",
    "| **Best for** | Ordinal categories, Tree models | Nominal categories, Linear models |\n",
    "| **Example** | Low=0, Medium=1, High=2 | Color_Red=1, Color_Blue=0 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "In this assignment, we:\n",
    "\n",
    "1. **Loaded and explored** the heart disease dataset\n",
    "2. **Preprocessed data** by handling missing values and encoding categorical variables\n",
    "3. **Built a Decision Tree** classifier with 80-20 train-test split\n",
    "4. **Tuned hyperparameters** to find the best model configuration\n",
    "5. **Evaluated the model** using accuracy, precision, recall, F1-score, and ROC-AUC\n",
    "6. **Visualized** the decision tree and feature importance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
