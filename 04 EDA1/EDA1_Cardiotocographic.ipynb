{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4: Exploratory Data Analysis (EDA) - Cardiotocographic Dataset\n",
    "\n",
    "## Objective\n",
    "Conduct a thorough exploratory analysis to uncover insights, identify patterns, and understand the dataset's underlying structure.\n",
    "\n",
    "## Dataset Columns\n",
    "- **LB** - Baseline Fetal Heart Rate\n",
    "- **AC** - Accelerations\n",
    "- **FM** - Fetal Movements\n",
    "- **UC** - Uterine Contractions\n",
    "- **DL** - Decelerations Late\n",
    "- **DS** - Decelerations Short\n",
    "- **DP** - Decelerations Prolonged\n",
    "- **ASTV** - Percentage of Time with Abnormal Short Term Variability\n",
    "- **MSTV** - Mean Value of Short Term Variability\n",
    "- **ALTV** - Percentage of Time with Abnormal Long Term Variability\n",
    "- **MLTV** - Mean Value of Long Term Variability\n",
    "- **Width** - Histogram Width\n",
    "- **Tendency** - Histogram Tendency\n",
    "- **NSP** - Fetal State (1=Normal, 2=Suspect, 3=Pathological)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1: Import Libraries and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('Cardiotocographic.csv')\n",
    "\n",
    "# Display basic info\n",
    "print(\"Dataset loaded successfully!\")\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2: Data Cleaning and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"=== Missing Values ===\")\n",
    "missing_values = df.isnull().sum()\n",
    "print(missing_values)\n",
    "\n",
    "# Check total missing\n",
    "total_missing = missing_values.sum()\n",
    "print(\"\\nTotal missing values:\", total_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types\n",
    "print(\"=== Data Types ===\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "duplicates = df.duplicated().sum()\n",
    "print(\"Number of duplicate rows:\", duplicates)\n",
    "\n",
    "# Remove duplicates if any\n",
    "if duplicates > 0:\n",
    "    df = df.drop_duplicates()\n",
    "    print(\"Duplicates removed. New shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values - fill with median (for numerical data)\n",
    "print(\"=== Handling Missing Values ===\")\n",
    "\n",
    "for column in df.columns:\n",
    "    missing_count = df[column].isnull().sum()\n",
    "    if missing_count > 0:\n",
    "        median_value = df[column].median()\n",
    "        df[column] = df[column].fillna(median_value)\n",
    "        print(\"Filled\", missing_count, \"missing values in\", column, \"with median:\", median_value)\n",
    "\n",
    "# Verify no missing values remain\n",
    "print(\"\\nRemaining missing values:\", df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3: Statistical Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get statistical summary using describe()\n",
    "print(\"=== Statistical Summary ===\")\n",
    "summary = df.describe()\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate additional statistics\n",
    "print(\"=== Detailed Statistics for Each Column ===\")\n",
    "\n",
    "for column in df.columns:\n",
    "    print(\"\\n\" + column + \":\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    # Mean\n",
    "    mean_val = df[column].mean()\n",
    "    print(\"  Mean:\", round(mean_val, 4))\n",
    "    \n",
    "    # Median\n",
    "    median_val = df[column].median()\n",
    "    print(\"  Median:\", round(median_val, 4))\n",
    "    \n",
    "    # Standard Deviation\n",
    "    std_val = df[column].std()\n",
    "    print(\"  Std Dev:\", round(std_val, 4))\n",
    "    \n",
    "    # IQR (Interquartile Range)\n",
    "    q1 = df[column].quantile(0.25)\n",
    "    q3 = df[column].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    print(\"  IQR:\", round(iqr, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4: Data Visualization\n",
    "\n",
    "### 4.1 Histograms - Distribution of Numerical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create histograms for all numerical columns\n",
    "numerical_cols = ['LB', 'AC', 'FM', 'UC', 'ASTV', 'MSTV', 'ALTV', 'MLTV', 'Width']\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(len(numerical_cols)):\n",
    "    column = numerical_cols[i]\n",
    "    axes[i].hist(df[column], bins=30, color='steelblue', edgecolor='black')\n",
    "    axes[i].set_title('Distribution of ' + column)\n",
    "    axes[i].set_xlabel(column)\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('histograms.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Boxplots - Identifying Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create boxplots\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(len(numerical_cols)):\n",
    "    column = numerical_cols[i]\n",
    "    axes[i].boxplot(df[column].dropna())\n",
    "    axes[i].set_title('Boxplot of ' + column)\n",
    "    axes[i].set_ylabel(column)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('boxplots.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Bar Chart - Fetal State (NSP) Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart for NSP (Fetal State)\n",
    "# NSP: 1 = Normal, 2 = Suspect, 3 = Pathological\n",
    "\n",
    "nsp_counts = df['NSP'].value_counts().sort_index()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "colors = ['green', 'orange', 'red']\n",
    "bars = plt.bar(nsp_counts.index, nsp_counts.values, color=colors, edgecolor='black')\n",
    "\n",
    "# Add labels\n",
    "labels = ['Normal', 'Suspect', 'Pathological']\n",
    "plt.xticks([1, 2, 3], labels)\n",
    "plt.xlabel('Fetal State')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Fetal State (NSP)')\n",
    "\n",
    "# Add count on top of bars\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             str(int(height)),\n",
    "             ha='center', va='bottom')\n",
    "\n",
    "plt.savefig('nsp_distribution.png')\n",
    "plt.show()\n",
    "\n",
    "# Print percentages\n",
    "print(\"\\nFetal State Distribution:\")\n",
    "total = len(df)\n",
    "for state, count in zip(labels, nsp_counts.values):\n",
    "    percentage = (count / total) * 100\n",
    "    print(state + \":\", count, \"(\", round(percentage, 2), \"%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Correlation Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation matrix\n",
    "correlation_matrix = df.corr()\n",
    "\n",
    "# Create heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, \n",
    "            annot=True, \n",
    "            fmt='.2f', \n",
    "            cmap='coolwarm',\n",
    "            center=0,\n",
    "            square=True)\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.tight_layout()\n",
    "plt.savefig('correlation_heatmap.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Scatter Plots - Relationships Between Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plots for key relationships\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Scatter 1: LB vs ASTV\n",
    "axes[0, 0].scatter(df['LB'], df['ASTV'], alpha=0.5, c='blue')\n",
    "axes[0, 0].set_xlabel('LB (Baseline Heart Rate)')\n",
    "axes[0, 0].set_ylabel('ASTV')\n",
    "axes[0, 0].set_title('LB vs ASTV')\n",
    "\n",
    "# Scatter 2: MSTV vs MLTV\n",
    "axes[0, 1].scatter(df['MSTV'], df['MLTV'], alpha=0.5, c='green')\n",
    "axes[0, 1].set_xlabel('MSTV')\n",
    "axes[0, 1].set_ylabel('MLTV')\n",
    "axes[0, 1].set_title('MSTV vs MLTV')\n",
    "\n",
    "# Scatter 3: Width vs LB\n",
    "axes[1, 0].scatter(df['Width'], df['LB'], alpha=0.5, c='red')\n",
    "axes[1, 0].set_xlabel('Width')\n",
    "axes[1, 0].set_ylabel('LB')\n",
    "axes[1, 0].set_title('Width vs LB')\n",
    "\n",
    "# Scatter 4: ASTV vs ALTV\n",
    "axes[1, 1].scatter(df['ASTV'], df['ALTV'], alpha=0.5, c='purple')\n",
    "axes[1, 1].set_xlabel('ASTV')\n",
    "axes[1, 1].set_ylabel('ALTV')\n",
    "axes[1, 1].set_title('ASTV vs ALTV')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('scatter_plots.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Violin Plots - Distribution by Fetal State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Violin plots showing distribution of key variables by NSP\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Violin 1: LB by NSP\n",
    "sns.violinplot(x='NSP', y='LB', data=df, ax=axes[0, 0], palette='Set2')\n",
    "axes[0, 0].set_title('LB Distribution by Fetal State')\n",
    "\n",
    "# Violin 2: ASTV by NSP\n",
    "sns.violinplot(x='NSP', y='ASTV', data=df, ax=axes[0, 1], palette='Set2')\n",
    "axes[0, 1].set_title('ASTV Distribution by Fetal State')\n",
    "\n",
    "# Violin 3: MSTV by NSP\n",
    "sns.violinplot(x='NSP', y='MSTV', data=df, ax=axes[1, 0], palette='Set2')\n",
    "axes[1, 0].set_title('MSTV Distribution by Fetal State')\n",
    "\n",
    "# Violin 4: Width by NSP\n",
    "sns.violinplot(x='NSP', y='Width', data=df, ax=axes[1, 1], palette='Set2')\n",
    "axes[1, 1].set_title('Width Distribution by Fetal State')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('violin_plots.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 5: Pattern Recognition and Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find top correlations\n",
    "print(\"=== Top Correlations ===\")\n",
    "\n",
    "# Get correlation values\n",
    "corr_pairs = []\n",
    "columns = df.columns.tolist()\n",
    "\n",
    "for i in range(len(columns)):\n",
    "    for j in range(i+1, len(columns)):\n",
    "        col1 = columns[i]\n",
    "        col2 = columns[j]\n",
    "        corr_value = correlation_matrix.loc[col1, col2]\n",
    "        corr_pairs.append((col1, col2, corr_value))\n",
    "\n",
    "# Sort by absolute correlation value\n",
    "corr_pairs.sort(key=lambda x: abs(x[2]), reverse=True)\n",
    "\n",
    "# Print top 10 correlations\n",
    "print(\"\\nTop 10 Strongest Correlations:\")\n",
    "for i in range(10):\n",
    "    pair = corr_pairs[i]\n",
    "    print(str(i+1) + \".\", pair[0], \"vs\", pair[1], \":\", round(pair[2], 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare means across fetal states\n",
    "print(\"=== Mean Values by Fetal State ===\")\n",
    "print(\"\\n(NSP: 1=Normal, 2=Suspect, 3=Pathological)\")\n",
    "\n",
    "grouped_means = df.groupby('NSP').mean()\n",
    "grouped_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier Detection using IQR method\n",
    "print(\"=== Outlier Detection ===\")\n",
    "\n",
    "for column in numerical_cols:\n",
    "    q1 = df[column].quantile(0.25)\n",
    "    q3 = df[column].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    \n",
    "    lower_bound = q1 - 1.5 * iqr\n",
    "    upper_bound = q3 + 1.5 * iqr\n",
    "    \n",
    "    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]\n",
    "    outlier_count = len(outliers)\n",
    "    \n",
    "    if outlier_count > 0:\n",
    "        percentage = (outlier_count / len(df)) * 100\n",
    "        print(column + \":\", outlier_count, \"outliers (\", round(percentage, 2), \"%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 6: Conclusion\n",
    "\n",
    "### Key Insights:\n",
    "\n",
    "1. **Dataset Overview:**\n",
    "   - The dataset contains cardiotocographic measurements for fetal health monitoring\n",
    "   - Most cases are classified as Normal (NSP=1)\n",
    "\n",
    "2. **Correlations Found:**\n",
    "   - Strong correlations exist between variability measures (ASTV, MSTV, ALTV, MLTV)\n",
    "   - Width shows correlation with heart rate measures\n",
    "\n",
    "3. **Differences by Fetal State:**\n",
    "   - Pathological cases (NSP=3) show different patterns in variability measures\n",
    "   - ASTV and ALTV values tend to be higher in abnormal cases\n",
    "\n",
    "4. **Outliers:**\n",
    "   - Several columns contain outliers that may need attention\n",
    "   - These could represent extreme but valid medical cases\n",
    "\n",
    "### Recommendations:\n",
    "- The variability measures (ASTV, MSTV, ALTV, MLTV) appear to be good indicators for fetal health\n",
    "- Machine learning models could use these features to predict fetal state\n",
    "- Outliers should be investigated with domain experts before removal"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
